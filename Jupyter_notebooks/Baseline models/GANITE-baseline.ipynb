{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.allow_soft_placement=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_pehe(tau_hat,tau):\n",
    "    return np.sqrt(np.mean(np.square(tau-tau_hat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def onehot(t,dim):\n",
    "    \n",
    "    m_samples = t.shape[0]\n",
    "    tt = np.zeros([m_samples,dim])\n",
    "    \n",
    "    for i in range(m_samples):\n",
    "        tt[i,np.int(t[i])] = 1\n",
    "        \n",
    "    return tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def load_ihdp(trial_id=0,filepath='./data/',istrain=True):\n",
    "    \n",
    "    if istrain:\n",
    "        data_file = filepath+'ihdp_npci_1-1000.train.npz'\n",
    "    else:\n",
    "        data_file = filepath+'ihdp_npci_1-1000.test.npz'\n",
    "        \n",
    "    data = np.load(data_file)\n",
    "    \n",
    "    x = data['x'][:,:,trial_id]\n",
    "    y = data['yf'][:,trial_id]\n",
    "    t = data['t'][:,trial_id]\n",
    "    ycf = data['ycf'][:,trial_id]\n",
    "    mu0 = data['mu0'][:,trial_id]\n",
    "    mu1 = data['mu1'][:,trial_id]\n",
    "    \n",
    "    return x,y,t,ycf,mu0,mu1\n",
    "\n",
    "ihdp_ind = 0\n",
    "\n",
    "VAL = True\n",
    "NORM = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y,T,Ycf,Mu0,Mu1 = load_ihdp(ihdp_ind)\n",
    "Tau = Mu1 - Mu0\n",
    "\n",
    "Y = np.reshape(Y,[-1,1])\n",
    "T = onehot(T,2)\n",
    "\n",
    "X_m = np.mean(X,axis=0,keepdims=True)\n",
    "X_std = np.std(X,axis=0,keepdims=True)\n",
    "X = (X-X_m)/X_std\n",
    "\n",
    "n_samples = X.shape[0]\n",
    "\n",
    "y_std = 1.\n",
    "\n",
    "if NORM:\n",
    "    y_m = np.mean(Y)\n",
    "    y_std = np.std(Y)\n",
    "\n",
    "    Y = (Y-y_m)/y_std\n",
    "\n",
    "    Tau = Tau/y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if VAL:\n",
    "\n",
    "    prob_train = 0.7\n",
    "\n",
    "    n_train_samples = int(np.ceil(prob_train*n_samples))\n",
    "\n",
    "    shuff_idx = np.array(range(n_samples))\n",
    "    # Shuffle the indices\n",
    "    # np.random.shuffle(shuff_idx)\n",
    "\n",
    "    train_idx = shuff_idx[:n_train_samples]\n",
    "    val_idx = shuff_idx[n_train_samples:]\n",
    "\n",
    "    X_val = X[val_idx]\n",
    "    Y_val = Y[val_idx]\n",
    "    T_val = T[val_idx]\n",
    "\n",
    "    X = X[train_idx]\n",
    "    Y = Y[train_idx]\n",
    "    T = T[train_idx]\n",
    "\n",
    "    n_samples = n_train_samples\n",
    "\n",
    "    Tau_val = Tau[val_idx]\n",
    "    Tau = Tau[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def keras_generator(X,Y,T,batch_size=128):\n",
    "    \n",
    "    num_steps = X.shape[0] // batch_size\n",
    "    \n",
    "    def generator():\n",
    "        \n",
    "        index = 0\n",
    "        n_samples = X.shape[0]\n",
    "        indexes = np.arange(n_samples)\n",
    "        np.random.shuffle(indexes)\n",
    "        \n",
    "        while True:\n",
    "            \n",
    "            if (index+1)*batch_size>n_samples:\n",
    "                np.random.shuffle(indexes)\n",
    "                index = 0\n",
    "            \n",
    "            ind = indexes[index*batch_size:(index+1)*batch_size]\n",
    "            index += 1\n",
    "            \n",
    "            xx = X[ind]\n",
    "            yy = Y[ind]\n",
    "            tt = T[ind]\n",
    "            \n",
    "            yield (xx,tt),yy\n",
    "            \n",
    "    return generator(), num_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_models.ganite import GANITE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_propensity_dropout = False\n",
    "imbalance_loss_weight = 0\n",
    "early_stopping_patience = 30\n",
    "early_stopping_on_pehe = 30\n",
    "num_layers = 3\n",
    "num_units = 60\n",
    "dropout = 0.\n",
    "batch_size = 100\n",
    "\n",
    "best_model_path = './best_model/'\n",
    "\n",
    "l2_weight = 0.000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "with_tensorboard = False # unclear\n",
    "n_jobs = 1 #unclear\n",
    "with_pehe_loss = False\n",
    "use_tarnet = True\n",
    "strength_of_assignment_bias = 0 # unclear\n",
    "\n",
    "ganite_weight_alpha = .1 # unclear\n",
    "ganite_weight_beta = .1 # unclear\n",
    "propensity_batch_probability = 0. # unclear\n",
    "\n",
    "match_on_covariates = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator,train_steps = keras_generator(X,Y.reshape([-1,]),T[:,1],batch_size=batch_size)\n",
    "val_generator,val_steps = keras_generator(X_val,Y_val.reshape([-1,]),T_val[:,1],batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = None\n",
    "num_randomised_neighbours = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params = {\n",
    "            \"with_propensity_dropout\": with_propensity_dropout,\n",
    "            \"imbalance_loss_weight\": imbalance_loss_weight,\n",
    "            \"early_stopping_patience\": early_stopping_patience,\n",
    "            \"early_stopping_on_pehe\": early_stopping_on_pehe,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"num_units\": num_units,\n",
    "            \"dropout\": dropout,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"num_treatments\": 2,\n",
    "            \"input_dim\": X.shape[1],\n",
    "            \"output_dim\": Y.shape[1],\n",
    "            \"best_model_path\": best_model_path,\n",
    "            \"l2_weight\": l2_weight,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"with_tensorboard\": with_tensorboard,\n",
    "            \"n_jobs\": n_jobs,\n",
    "            \"benchmark\": benchmark,\n",
    "            \"with_pehe_loss\": with_pehe_loss,\n",
    "            \"use_tarnet\": use_tarnet,\n",
    "            \"strength_of_assignment_bias\": strength_of_assignment_bias,\n",
    "            \"ganite_weight_alpha\": ganite_weight_alpha,\n",
    "            \"ganite_weight_beta\": ganite_weight_beta,\n",
    "            \"propensity_batch_probability\": propensity_batch_probability,\n",
    "            \"match_on_covariates\": match_on_covariates,\n",
    "            \"num_randomised_neighbours\": num_randomised_neighbours,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_type = GANITE\n",
    "model = method_type()\n",
    "model.build(**network_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/cytao/Projects/Causal/cfrnet/baseline_models/ganite.py:370: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cytao/Projects/Causal/cfrnet/baseline_models/ganite.py:377: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cytao/Projects/Causal/cfrnet/baseline_models/ganite.py:341: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/cytao/Projects/Causal/cfrnet/baseline_models/ganite.py:387: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [0000/0050] xx TRAIN: G=-0.366 D=0.576 VAL: G=-0.396 D=0.524\n",
      "Epoch [0001/0050] :: TRAIN: G=-0.404 D=0.485 VAL: G=-0.392 D=0.516\n",
      "Epoch [0002/0050] :: TRAIN: G=-0.329 D=0.508 VAL: G=-0.382 D=0.500\n",
      "Epoch [0003/0050] :: TRAIN: G=-0.396 D=0.403 VAL: G=-0.372 D=0.477\n",
      "Epoch [0004/0050] :: TRAIN: G=-0.423 D=0.347 VAL: G=-0.380 D=0.468\n",
      "Epoch [0005/0050] :: TRAIN: G=-0.428 D=0.392 VAL: G=-0.392 D=0.467\n",
      "Epoch [0006/0050] :: TRAIN: G=-0.328 D=0.427 VAL: G=-0.376 D=0.454\n",
      "Epoch [0007/0050] :: TRAIN: G=-0.347 D=0.420 VAL: G=-0.382 D=0.447\n",
      "Epoch [0008/0050] :: TRAIN: G=-0.283 D=0.431 VAL: G=-0.382 D=0.450\n",
      "Epoch [0009/0050] :: TRAIN: G=-0.289 D=0.331 VAL: G=-0.377 D=0.441\n",
      "Epoch [0010/0050] :: TRAIN: G=-0.299 D=0.370 VAL: G=-0.369 D=0.456\n",
      "Epoch [0011/0050] :: TRAIN: G=-0.245 D=0.382 VAL: G=-0.378 D=0.458\n",
      "Epoch [0012/0050] :: TRAIN: G=-0.346 D=0.322 VAL: G=-0.382 D=0.462\n",
      "Epoch [0013/0050] xx TRAIN: G=-0.374 D=0.406 VAL: G=-0.409 D=0.496\n",
      "Epoch [0014/0050] xx TRAIN: G=-0.436 D=0.507 VAL: G=-0.438 D=0.523\n",
      "Epoch [0015/0050] xx TRAIN: G=-0.306 D=0.540 VAL: G=-0.448 D=0.570\n",
      "Epoch [0016/0050] :: TRAIN: G=-0.430 D=0.496 VAL: G=-0.420 D=0.557\n",
      "Epoch [0017/0050] :: TRAIN: G=-0.294 D=0.417 VAL: G=-0.355 D=0.520\n",
      "Epoch [0018/0050] :: TRAIN: G=-0.286 D=0.425 VAL: G=-0.334 D=0.509\n",
      "Epoch [0019/0050] :: TRAIN: G=-0.342 D=0.353 VAL: G=-0.337 D=0.507\n",
      "Epoch [0020/0050] :: TRAIN: G=-0.516 D=0.362 VAL: G=-0.349 D=0.498\n",
      "Epoch [0021/0050] :: TRAIN: G=-0.440 D=0.407 VAL: G=-0.368 D=0.483\n",
      "Epoch [0022/0050] :: TRAIN: G=-0.392 D=0.374 VAL: G=-0.378 D=0.464\n",
      "Epoch [0023/0050] :: TRAIN: G=-0.289 D=0.431 VAL: G=-0.397 D=0.479\n",
      "Epoch [0024/0050] :: TRAIN: G=-0.384 D=0.343 VAL: G=-0.419 D=0.492\n",
      "Epoch [0025/0050] :: TRAIN: G=-0.213 D=0.418 VAL: G=-0.419 D=0.490\n",
      "Epoch [0026/0050] :: TRAIN: G=-0.280 D=0.421 VAL: G=-0.424 D=0.489\n",
      "Epoch [0027/0050] :: TRAIN: G=-0.350 D=0.366 VAL: G=-0.440 D=0.498\n",
      "Epoch [0028/0050] :: TRAIN: G=-0.349 D=0.333 VAL: G=-0.443 D=0.489\n",
      "Epoch [0029/0050] :: TRAIN: G=-0.303 D=0.347 VAL: G=-0.443 D=0.503\n",
      "Epoch [0030/0050] :: TRAIN: G=-0.369 D=0.462 VAL: G=-0.441 D=0.504\n",
      "Epoch [0031/0050] :: TRAIN: G=-0.326 D=0.427 VAL: G=-0.428 D=0.495\n",
      "Epoch [0032/0050] :: TRAIN: G=-0.366 D=0.462 VAL: G=-0.419 D=0.479\n",
      "Epoch [0033/0050] :: TRAIN: G=-0.348 D=0.379 VAL: G=-0.408 D=0.476\n",
      "Epoch [0034/0050] :: TRAIN: G=-0.362 D=0.410 VAL: G=-0.413 D=0.468\n",
      "Epoch [0035/0050] :: TRAIN: G=-0.353 D=0.329 VAL: G=-0.408 D=0.465\n",
      "Epoch [0036/0050] :: TRAIN: G=-0.354 D=0.423 VAL: G=-0.408 D=0.463\n",
      "Epoch [0037/0050] :: TRAIN: G=-0.266 D=0.416 VAL: G=-0.410 D=0.464\n",
      "Epoch [0038/0050] :: TRAIN: G=-0.344 D=0.415 VAL: G=-0.409 D=0.459\n",
      "Epoch [0039/0050] :: TRAIN: G=-0.323 D=0.431 VAL: G=-0.410 D=0.461\n",
      "Epoch [0040/0050] :: TRAIN: G=-0.352 D=0.432 VAL: G=-0.402 D=0.464\n",
      "Epoch [0041/0050] :: TRAIN: G=-0.336 D=0.380 VAL: G=-0.414 D=0.462\n",
      "Epoch [0042/0050] :: TRAIN: G=-0.377 D=0.429 VAL: G=-0.429 D=0.474\n",
      "Epoch [0043/0050] :: TRAIN: G=-0.287 D=0.364 VAL: G=-0.425 D=0.481\n",
      "Epoch [0044/0050] :: TRAIN: G=-0.331 D=0.397 VAL: G=-0.428 D=0.482\n",
      "Epoch [0045/0050] :: TRAIN: G=-0.291 D=0.450 VAL: G=-0.429 D=0.473\n",
      "Epoch [0000/0050] xx TRAIN: G=-1.348 D=1.359 VAL: G=-1.287 D=1.362\n",
      "Epoch [0001/0050] :: TRAIN: G=-0.871 D=0.727 VAL: G=-0.711 D=0.771\n",
      "Epoch [0002/0050] :: TRAIN: G=-0.127 D=0.086 VAL: G=-0.053 D=0.114\n",
      "Epoch [0003/0050] :: TRAIN: G=0.046 D=0.005 VAL: G=0.058 D=0.005\n",
      "Epoch [0004/0050] :: TRAIN: G=0.049 D=0.000 VAL: G=0.056 D=0.001\n",
      "Epoch [0005/0050] :: TRAIN: G=0.043 D=0.000 VAL: G=0.049 D=0.000\n",
      "Epoch [0006/0050] :: TRAIN: G=0.046 D=0.000 VAL: G=0.048 D=0.000\n",
      "Epoch [0007/0050] :: TRAIN: G=0.042 D=0.000 VAL: G=0.048 D=0.000\n",
      "Epoch [0008/0050] :: TRAIN: G=0.040 D=0.000 VAL: G=0.047 D=0.000\n",
      "Epoch [0009/0050] :: TRAIN: G=0.044 D=0.000 VAL: G=0.048 D=0.000\n",
      "Epoch [0010/0050] :: TRAIN: G=0.038 D=0.000 VAL: G=0.048 D=0.000\n",
      "Epoch [0011/0050] :: TRAIN: G=0.040 D=0.000 VAL: G=0.048 D=0.000\n",
      "Epoch [0012/0050] :: TRAIN: G=0.040 D=0.000 VAL: G=0.048 D=0.000\n",
      "Epoch [0013/0050] :: TRAIN: G=0.044 D=0.000 VAL: G=0.048 D=0.000\n",
      "Epoch [0014/0050] :: TRAIN: G=0.037 D=0.000 VAL: G=0.048 D=0.000\n",
      "Epoch [0015/0050] :: TRAIN: G=0.044 D=0.000 VAL: G=0.048 D=0.000\n",
      "Epoch [0016/0050] :: TRAIN: G=0.040 D=0.000 VAL: G=0.047 D=0.000\n",
      "Epoch [0017/0050] :: TRAIN: G=0.036 D=0.000 VAL: G=0.046 D=0.000\n",
      "Epoch [0018/0050] :: TRAIN: G=0.042 D=0.000 VAL: G=0.047 D=0.000\n",
      "Epoch [0019/0050] :: TRAIN: G=0.041 D=0.000 VAL: G=0.047 D=0.000\n",
      "Epoch [0020/0050] :: TRAIN: G=0.038 D=0.000 VAL: G=0.046 D=0.000\n",
      "Epoch [0021/0050] :: TRAIN: G=0.040 D=0.000 VAL: G=0.047 D=0.000\n",
      "Epoch [0022/0050] :: TRAIN: G=0.036 D=0.000 VAL: G=0.046 D=0.000\n",
      "Epoch [0023/0050] :: TRAIN: G=0.038 D=0.000 VAL: G=0.046 D=0.000\n",
      "Epoch [0024/0050] :: TRAIN: G=0.040 D=0.000 VAL: G=0.046 D=0.000\n",
      "Epoch [0025/0050] :: TRAIN: G=0.041 D=0.000 VAL: G=0.047 D=0.000\n",
      "Epoch [0026/0050] :: TRAIN: G=0.039 D=0.000 VAL: G=0.047 D=0.000\n",
      "Epoch [0027/0050] :: TRAIN: G=0.036 D=0.000 VAL: G=0.047 D=0.000\n",
      "Epoch [0028/0050] :: TRAIN: G=0.042 D=0.000 VAL: G=0.047 D=0.000\n",
      "Epoch [0029/0050] :: TRAIN: G=0.045 D=0.000 VAL: G=0.047 D=0.000\n",
      "Epoch [0030/0050] :: TRAIN: G=0.039 D=0.000 VAL: G=0.047 D=0.000\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50 # maximal number of epoches\n",
    "\n",
    "model.fit_generator(train_generator=train_generator,\n",
    "                                train_steps=train_steps,\n",
    "                                num_epochs=num_epochs,\n",
    "                                val_generator=val_generator,\n",
    "                                val_steps=val_steps,\n",
    "                                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict([X,T])\n",
    "\n",
    "tau_hat = y_pred[:,1] - y_pred[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pehe_mkl = eval_pehe(tau_hat, Tau)*y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2184082726923555\n"
     ]
    }
   ],
   "source": [
    "print(pehe_mkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAASCklEQVR4nO3df6xk5V3H8c/HLRQTiLRdUhDY3iUSFYkRMsH+MEpaSJA2xapNWhMtsWZtTJM2MTGrSzQaElGTJhpq6g0QaUIo2hbB7hJcLE3TP3bbC1lYlm0pxZpC1nJXI+1qAtJ+/WPmktm7c2bOzHnmnOc5834lG+bOHM55npl7P/Oc53zPOY4IAQDK9SNdNwAA0AxBDgCFI8gBoHAEOQAUjiAHgMK9rouN7ty5M9bW1rrYNAAU67HHHjsZERdsf76TIF9bW9PGxkYXmwaAYtn+90nPM7UCAIUjyAGgcAQ5ABSOIAeAwhHkAFC4TqpWAGBVDG49qJOnXjnj+Z3nnq2NW65Pso3GI3Lb59j+qu0nbB+z/acpGgYAfTApxKc9v4gUI/KXJb0zIk7ZPkvSV2w/FBGHEqwbADBD4yCP4QXNT41+PGv0j4ucA0BLkhzstL3D9hFJL0o6GBGHJyyzx/aG7Y3Nzc0UmwUAKFGQR8QPIuLnJF0i6RrbV05YZj0iBhExuOCCMy4VAABYUNKqlYj4b9uPSrpB0lMp1w0ApaiqVFmWFFUrF9g+f/T4RyVdL+nrTdcLAKVqM8SlNCPyiyTdbXuHhl8M/xARX0iwXgDI1rT68HnWkaKWPEXVypOSrmrcEgDIXJ0pk3lG46lG7pyiDwA1tT1lUhdBDgCFI8gBoHAEOQAUjiAHgMIR5ABQ0zylhW0iyAGghrbP1pwHQQ4AM+Qc4hJ3CAIASfmH9TSMyAFA+Z7sUwdBDgCFY2oFQHHauKFxSRiRAyhOGzc0bkOqckZG5ABWTi4HNlPtPTAiB7BycgjxlBiRA+ilFDd+KAUjcgC91Jd59DoIcgDFqRpV93G0XQdTKwCKQMlhNUbkAIqwSlMl8yLIAaBwBDmAXlql+XLmyAH00vi8+dre/R22ZPkYkQPovb6PzglyAEVoUnLY96oWplYAFGE8jMdLEU+eeuW1qZNVLUUkyAEUp04pYi4XxmoDQQ5gabo8iWdVQlxijhzAEnESTzsIcgAoXOMgt32p7UdtP237mO2PpWgYAPRZypLIFHPkr0r6/Yh43PZ5kh6zfTAink6wbgArYp759J3nnj1xWSv/k3+WcXygcZBHxAlJJ0aPv2/7uKSLJRHkAKaqU1ky6fXxINy9d79i9DjOWDI/W+WSKQM96Ry57TVJV0k6POG1PbY3bG9sbm6m3CyATE2bPljbuz/JQc8SwnuSlAd8k5Uf2j5X0uckfTwivrf99YhYl7QuSYPBoNT3HsAcVul6J11KMiK3fZaGIX5PRHw+xToBAPWkqFqxpDslHY+ITzRvEgBgHimmVt4h6TclHbV9ZPTcH0XEgQTrBrDitubZV+mU+3mlqFr5ioZVPwCwNIR4Nc7sBNCKRU+AIcBnI8gBtKJJzTQVL9Nx9UMAp+nyioVYDCNyAKdZ5hUL+37Lta4wIgfQmqq7/KAZRuQAOrHq0zS5Xf0QACS1N79edfXD3C3rOANBDiCZtu4IVGKIf/u2dy9t3UytADhN1S4/ByrzxYgcwGmWNXc9Xgu+rCmGrVHvqh1IJciBFdZVzfiyQ3bjlutX6iQighwowLICl7vc9wNBDhSglMDNqZokp7ZIky8zkGrPhyAHkMz2UJo1vZE6bEubTknVd4IcQGe4FVwalB8CyALljYtjRA70UN2Do1VTG12Eaq6VJlvvRdX7lMM8PEEOFGDewK17cLTL6520UVeeyrS25fDlQ5ADBcg55MYteiLO1v+Tywh33MlTr5wR1qm+eFLt+TBHDiCZaSE861oju/fubyXEU4TneDunXdJgVp9TfUEzIgeQhWhpOxu3XK/de/cn214Oe0sEOYCFlHo9k9179+vfJoyUlzXX3cYBZYIc6KE2wqPEEJfaG/lvaWPETpADPZTD7n5pmh5o7fKm1QQ5sMLqTo80DaPcT/ZJMU3U5fVwqFoBVljdkNm+3ODWg3NtJ/c9hFKnibYwIgcwt3mDb97gn6aqpK+NE3NyPXGJIAdWQNcVJqWPeLdsnRyUW6AT5EAGln2grC9BmmKuPfUJQTlIEuS275L0HkkvRsSVKdYJrJJSbhzRpaZ3oV/mXeylbi9AlmpE/veSbpf06UTrA5CRnKpOFpkmaqP9XU61JAnyiPiy7bUU6wLQrjoj1cGtB7O4yp80ey9lVn+6Pl6wDJQfApipT8HXp75saS3Ibe+xvWF7Y3Nzs63NAtD0K/TlIJd21JVbe1urWomIdUnrkjQYDNq+3AGQtWUfKJs0f7s1xbCsa21PM2n6Y9rUTQ7BueyDpU1QfghkoIsDZcuqlNkKvJRz6qnen5QnJuUkVfnhvZKulbTT9vOS/iQi7kyxbqA0XV48KSfz7mXMWr7OQcpZI/c+zo9L6apWPphiPUAf9LEmfJErA877pTVr+SZ3H0oh53uMMrUCYKbtoZVLKWJXcvtSpvwQwNxyr4JZNYzIgRVVNV1iTR5xj08n5DStkErTG0t0iSAHVlRVGFdNm5w89YoGtx4sOsSnHVCd1K9SppAIciCxaWGRe0XLrPK8ZY1YU70vdStbcnivUyLIgcSmhcS00e6s6Yw2tDm1UCd0t16vW/9dp/3z9LHLKxrOgyAHMpbrnG2KEfQ8fZu27DJDtZSRO0EOYG51auXbmkYqJWyXifJDAEsxLexLOYhYCoIcQG25zQ1jiKkVoEW51yrPOrjX9mh63i+OOu/vPOvMvcpoC0EOtKjqj39aYLRpkYqb1CaFZN3qkdThWsp1cwhyIAM5je62m/fWaIucNPTt29792naqrpGe8/XAu0aQAwtIvcvd1S58ne3OO/rcWn7eaaRpy+Y2As4NQQ4sIPUud1e78MvcLldMbA9BDmAigrccBDmA3mo6ZcUp+gDQsaZTRzkfhB7HCUEAklp0tDrt/8ttBJwbRuTAAlLvcne1C5/iBKW6ZYGz+ljK6DdHBDmwgNSh01WItXkzhZR9LOWMy7YwtQLgNLlPY0w7QWlV680ZkQM4zaQRbS6XEJD6eWOIpghyADOVOl2x7HbnMsXD1AoALCiXKR5G5MAKymUkiTQYkQMrKJeRZGp9m/uuixE5gE4sulcw7QDmqu5NEOQAWlPn2uazXl/VsJ6GqRUArSl96ma7qqmctqd4kozIbd8g6a8l7ZB0R0TclmK9AJCzXPYOGo/Ibe+Q9ElJvyzpCkkftH1F0/UCWJ5cRpJII8WI/BpJz0bEc5Jk+zOSbpL0dIJ1A1iCXEaSSCNFkF8s6TtjPz8v6ee3L2R7j6Q9krRr164EmwVQR2k1413sFZT2Hm3XWtVKRKxLWpekwWAQbW0XKFmKgMmpZjzX0sGc3qNFpAjyFyRdOvbzJaPnADRUesBsV8LotkQpgvxrki63vVvDAP+ApN9IsF4UovTdUpwu1efJ70V7Ggd5RLxq+6OSHtaw/PCuiDjWuGUoRt9Gjasu1efJ70V7ksyRR8QBSQdSrAurjVEcMD9O0UdWUozi+DLAvEq/AQVBjuLMCuo+7dKXHjClKP0LniBHa1KNlPsU1LOUHjBoB0GOxuqOGksK4EW+dPoypZNqL4C9ifYQ5GispJCqa5EvnVy/qOYN1FSfZx9/L3JFkCMrjOLSI1D7jyBHVlKEDl8GWDUEOYozK6gZgWLVEORoTaqRMkENnI4gR2tKCuBFvnSY0kFXHNH+FWUHg0FsbGy0vl0AKJntxyJisP15br4MAIUjyAGgcAQ5ABSOIAeAwhHkAFA4yg9RrL5cpApoihE5ipXrRaqAthHkAFA4ghwACkeQA0DhCHIAKBxVKz2yalUcXKQKGCLIe2TVqjj6+OUELIIgB9C6Vdt7XDbmyAG0btX2HpeNIAeAwhHkAFA4grxHqqo1qOIA+o2DnT3CQSJgNTUakdt+v+1jtn9o+4z7yAHAJOw9ptV0RP6UpF+V9HcJ2gJgCXIs9WPvMa1GQR4RxyXJdprWAEiOUr/+a22O3PYeSXskadeuXW1tFoXJcfQI5G5mkNt+RNKFE17aFxEP1N1QRKxLWpekwWAQtVuIlcLoEZjfzCCPiOvaaAgAYDHUkQNA4ZqWH77P9vOS3iZpv+2H0zQLQCqU+vVf06qV+yXdn6gtAJaAg8T9x9QKssLoEZgfp+gjK4wegfkxIgeAwhHkAFA4plYAtIKzdpeHETmAVnDW7vIQ5ABQOIIcAApHkANA4QhyACgcQQ6gFZy1uzyUHwJoBSWGy8OIHAAKR5ADQOEIcgAoHEEOAIUjyAGgcAQ5ABSOIAeAwhVRR87lLwGgWhEjci5/CQDVighyAEA1ghwACkeQA0DhCHIAKFwRQc7lLwGgWhHlh5QYAkC1IkbkAIBqBDkAFI4gB4DCNQpy239l++u2n7R9v+3zUzUMAFBP0xH5QUlXRsTPSnpG0h82bxIAYB6Ngjwi/iUiXh39eEjSJc2bBACYR8ryw9+WdF/Vi7b3SNojSbt27Uq4WdTFVSSBfpoZ5LYfkXThhJf2RcQDo2X2SXpV0j1V64mIdUnrkjQYDGKh1qIRriIJ9NPMII+I66a9bvtmSe+R9K6IIKABoGWNplZs3yDpDyT9UkT8b5omAQDm0bRq5XZJ50k6aPuI7U8laBMAYA6NRuQR8ROpGgIAWAxndq4QriIJ9FMRVz9EGpQYAv3EiBwACkeQA0DhCHIAKBxBDgCFI8gBoHDu4qx625uS/kfSydY3vhw71Y++9KUfUn/6Qj/y02Vf3hIRF2x/spMglyTbGxEx6GTjifWlL33ph9SfvtCP/OTYF6ZWAKBwBDkAFK7LIF/vcNup9aUvfemH1J++0I/8ZNeXzubIAQBpMLUCAIUjyAGgcK0Fue332z5m+4e2K0t3bN9g+xu2n7W9t632zcP2G20ftP3N0X/fULHcD0Y33Dhi+8G221ll1nts+/W27xu9ftj2WvutnK1GP262vTn2GfxOF+2cxfZdtl+0/VTF67b9N6N+Pmn76rbbWEeNflxr+6Wxz+OP225jXbYvtf2o7adHufWxCcvk87lERCv/JP20pJ+U9CVJg4pldkj6lqTLJJ0t6QlJV7TVxjn68peS9o4e75X0FxXLneq6rYu8x5J+T9KnRo8/IOm+rtu9YD9ulnR7122t0ZdflHS1pKcqXr9R0kOSLOmtkg533eYF+3GtpC903c6afblI0tWjx+dJembC71c2n0trI/KIOB4R35ix2DWSno2I5yLiFUmfkXTT8ls3t5sk3T16fLekX+mwLfOq8x6P9++zkt5l2y22sY5SfldmiogvS/qvKYvcJOnTMXRI0vm2L2qndfXV6EcxIuJERDw+evx9ScclXbxtsWw+l9zmyC+W9J2xn5/XmW9eDt4cESdGj/9D0psrljvH9obtQ7ZzCfs67/Fry0TEq5JekvSmVlpXX93flV8b7fZ+1val7TQtuVL+Lup4m+0nbD9k+2e6bkwdo6nFqyQd3vZSNp9L0jsE2X5E0oUTXtoXEQ+k3NayTevL+A8REbarajjfEhEv2L5M0hdtH42Ib6VuKyr9s6R7I+Jl27+r4V7GOztu0yp7XMO/iVO2b5T0T5Iu77hNU9k+V9LnJH08Ir7XdXuqJA3yiLiu4SpekDQ+arpk9FzrpvXF9ndtXxQRJ0a7Ui9WrOOF0X+fs/0lDb/Vuw7yOu/x1jLP236dpB+T9J/tNK+2mf2IiPE236HhsY0SZfN30cR4EEbEAdt/a3tnRGR5MS3bZ2kY4vdExOcnLJLN55Lb1MrXJF1ue7ftszU80JZNtceYByV9aPT4Q5LO2Nuw/Qbbrx893inpHZKebq2F1eq8x+P9+3VJX4zR0Z2MzOzHtvnK92o4z1miByX91qhK4q2SXhqb2iuG7Qu3jrXYvkbD/MltgCBpWJEi6U5JxyPiExWL5fO5tHgU+H0aziG9LOm7kh4ePf/jkg5sOxL8jIYj131dHQWe0Zc3SfpXSd+U9IikN46eH0i6Y/T47ZKOalhNcVTSh7tu97T3WNKfSXrv6PE5kv5R0rOSvirpsq7bvGA//lzSsdFn8Kikn+q6zRX9uFfSCUn/N/ob+bCkj0j6yOh1S/rkqJ9HVVH11fW/Gv346NjncUjS27tu85S+/IKkkPSkpCOjfzfm+rlwij4AFC63qRUAwJwIcgAoHEEOAIUjyAGgcAQ5ABSOIAeAwhHkAFC4/wepO6LXsaQ/6QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.plot(Tau,tau_hat,'s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
